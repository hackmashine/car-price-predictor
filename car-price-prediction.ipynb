{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7673611,"sourceType":"datasetVersion","datasetId":4476093}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from catboost import CatBoostRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport pandas as pd\n\n# Загружаем данные\ndf = pd.read_csv(\"/kaggle/input/vehicle-sales-data/car_prices.csv\")\n\n# Удаляем строки, где нет цены\ndf = df.dropna(subset=[\"sellingprice\"])\n\n# Целевая переменная\ny = df[\"sellingprice\"]\n\n# Признаки (выкинем явно ненужные — vin, saledate)\nX = df.drop(columns=[\"sellingprice\", \"vin\", \"saledate\"])\n\n# Категориальные признаки (строковые)\ncat_features = [\"make\", \"model\", \"trim\", \"body\", \"transmission\", \"color\", \"interior\", \"state\", \"seller\"]\n\n# Делим выборку\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Заполняем NaN в категориальных признаках\nfor col in cat_features:\n    X_train[col] = X_train[col].astype(str).fillna(\"Unknown\")\n    X_test[col] = X_test[col].astype(str).fillna(\"Unknown\")\n\n# CatBoost с категориальными признаками\ncat_model = CatBoostRegressor(\n    depth=6,\n    iterations=500,\n    learning_rate=0.1,\n    loss_function=\"MAE\",\n    verbose=100\n)\n\n# Обучение\ncat_model.fit(X_train, y_train, cat_features=cat_features)\n\n# Предсказания\ny_pred = cat_model.predict(X_test)\n\n# Ошибка\nmae = mean_absolute_error(y_test, y_pred)\nprint(\"CatBoost MAE с категориальными признаками:\", mae)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T18:17:09.203264Z","iopub.execute_input":"2025-09-03T18:17:09.203624Z","iopub.status.idle":"2025-09-03T18:21:34.621151Z","shell.execute_reply.started":"2025-09-03T18:17:09.203597Z","shell.execute_reply":"2025-09-03T18:21:34.619912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.pyplot as plt\n\n# ===============================\n# 1. Загружаем данные\n# ===============================\ndf = pd.read_csv(\"/kaggle/input/vehicle-sales-data/car_prices.csv\")\n\n# Целевая переменная\ny = df[\"sellingprice\"]\n\n# Признаки\nX = df.drop(columns=[\"sellingprice\", \"vin\", \"saledate\"])\n\n# Категориальные признаки\ncat_features = [\"make\", \"model\", \"trim\", \"body\", \"transmission\", \n                \"color\", \"interior\", \"state\", \"seller\"]\n\n# Обрабатываем пропуски\nfor col in cat_features:\n    X[col] = X[col].astype(str).fillna(\"Unknown\")\n\n# Убираем строки с NaN в целевой переменной\nmask = ~y.isna()\nX = X[mask]\ny = y[mask]\n\n# Train/Test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# ===============================\n# 2. Финальная модель (лучшие параметры Trial 4)\n# ===============================\nbest_params = {\n    \"depth\": 10,\n    \"iterations\": 894,\n    \"learning_rate\": 0.15903410295472148,\n    \"l2_leaf_reg\": 5.276540089873177,\n    \"random_strength\": 18.860360227609693,\n    \"loss_function\": \"MAE\",\n    \"silent\": False,\n    \"random_state\": 42\n}\n\nfinal_model = CatBoostRegressor(**best_params)\nfinal_model.fit(X_train, y_train, cat_features=cat_features, verbose=100)\n\n# Проверяем на тесте\ny_pred = final_model.predict(X_test)\nfinal_mae = mean_absolute_error(y_test, y_pred)\nprint(\"Финальный MAE на тесте:\", final_mae)\n\n# ===============================\n# 3. Визуализация важности признаков\n# ===============================\nfeature_importances = final_model.get_feature_importance(prettified=True)\nprint(feature_importances)\n\nplt.figure(figsize=(10,6))\nplt.barh(feature_importances[\"Feature Id\"], feature_importances[\"Importances\"])\nplt.xlabel(\"Важность признака\")\nplt.ylabel(\"Признак\")\nplt.title(\"Feature Importance\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T20:53:38.288603Z","iopub.execute_input":"2025-09-03T20:53:38.289910Z","iopub.status.idle":"2025-09-03T21:11:37.674940Z","shell.execute_reply.started":"2025-09-03T20:53:38.289830Z","shell.execute_reply":"2025-09-03T21:11:37.673142Z"}},"outputs":[],"execution_count":null}]}